# gguf-quant-queue

proper readme to follow when I can be bothered to, here's a temporary one.

it's based on the same ideas as the exl2 one: https://github.com/lucyknada/exl2-quant-queue/blob/main/README.md

it needs llama-gguf-split, llama-quantize hf_transfer, huggingface-cli, convert_hf_to_gguf.py

which all might be called something different now (or not) in llama-cpp upstream
